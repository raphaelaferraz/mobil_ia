{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly_express in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly_express) (2.0.3)\n",
      "Requirement already satisfied: plotly>=4.1.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly_express) (5.16.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly_express) (0.14.0)\n",
      "Requirement already satisfied: scipy>=0.18 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly_express) (1.11.2)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly_express) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly_express) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.20.0->plotly_express) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.20.0->plotly_express) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.20.0->plotly_express) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from patsy>=0.5->plotly_express) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly>=4.1.0->plotly_express) (8.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly>=4.1.0->plotly_express) (23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: missingno in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from missingno) (1.25.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from missingno) (3.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from missingno) (1.11.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from missingno) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->missingno) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->missingno) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->missingno) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->missingno) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->missingno) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->missingno) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn->missingno) (2.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.25->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.25->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scipy) (1.25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: prophet in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (1.25.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (3.7.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (2.0.3)\n",
      "Requirement already satisfied: LunarCalendar>=0.0.9 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (0.0.9)\n",
      "Requirement already satisfied: convertdate>=2.1.2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (2.4.0)\n",
      "Requirement already satisfied: holidays>=0.25 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (0.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from prophet) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (4.66.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (6.0.1)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from convertdate>=2.1.2->prophet) (0.5.12)\n",
      "Requirement already satisfied: ephem>=3.7.5.3 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from LunarCalendar>=0.0.9->prophet) (4.1.4)\n",
      "Requirement already satisfied: pytz in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from LunarCalendar>=0.0.9->prophet) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inteli\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.0->prophet) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "     ---------------------------------------- 0.0/100.3 kB ? eta -:--:--\n",
      "     ----------- ------------------------- 30.7/100.3 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 100.3/100.3 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-optimize) (1.3.2)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize)\n",
      "  Obtaining dependency information for pyaml>=16.9 from https://files.pythonhosted.org/packages/56/db/01bc52d991716ccac7366b6e763fdaaf7b57910dbc2f85466c997f915284/pyaml-23.9.6-py3-none-any.whl.metadata\n",
      "  Downloading pyaml-23.9.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-optimize) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-optimize) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-optimize) (1.3.0)\n",
      "Collecting PyYAML (from pyaml>=16.9->scikit-optimize)\n",
      "  Obtaining dependency information for PyYAML from https://files.pythonhosted.org/packages/b3/34/65bb4b2d7908044963ebf614fe0fdb080773fc7030d7e39c8d3eddcd4257/PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
      "Downloading pyaml-23.9.6-py3-none-any.whl (22 kB)\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB 8.4 MB/s eta 0:00:00\n",
      "Installing collected packages: PyYAML, pyaml, scikit-optimize\n",
      "Successfully installed PyYAML-6.0.1 pyaml-23.9.6 scikit-optimize-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install plotly_express\n",
    "%pip install missingno\n",
    "%pip install scipy\n",
    "%pip install scikit-learn\n",
    "%pip install prophet \n",
    "%pip install scikit-optimize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>sku</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>shipment_type</th>\n",
       "      <th>anchor_category</th>\n",
       "      <th>product_department</th>\n",
       "      <th>product_category</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>process_costing</th>\n",
       "      <th>sku_color</th>\n",
       "      <th>price_status</th>\n",
       "      <th>winning_price</th>\n",
       "      <th>items_sold</th>\n",
       "      <th>avg_website_visits_last_week</th>\n",
       "      <th>stock_qty</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>value_dollar</th>\n",
       "      <th>rate_employability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>549</td>\n",
       "      <td>1099.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1488.07</td>\n",
       "      <td>0</td>\n",
       "      <td>17.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0949</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>669</td>\n",
       "      <td>413.99</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>392.58</td>\n",
       "      <td>0</td>\n",
       "      <td>48.857143</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0949</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>745</td>\n",
       "      <td>949.99</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1110.69</td>\n",
       "      <td>1</td>\n",
       "      <td>22.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0949</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "      <td>2949.99</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3457.04</td>\n",
       "      <td>0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0949</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>697</td>\n",
       "      <td>657.99</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>529.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0949</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740089</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>504.88</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>339.00</td>\n",
       "      <td>0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.8222</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740090</th>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>1717.95</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1717.95</td>\n",
       "      <td>0</td>\n",
       "      <td>154.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.8222</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740091</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>1659.88</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1093.68</td>\n",
       "      <td>0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.8222</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740092</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>909.96</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>899.96</td>\n",
       "      <td>0</td>\n",
       "      <td>32.714286</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.8222</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740093</th>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "      <td>619.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>659.98</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>136</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.8222</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740094 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        weekday_name  sku  unit_price  shipment_type  anchor_category  \\\n",
       "0                  6  549     1099.99              0               24   \n",
       "1                  6  669      413.99              0               13   \n",
       "2                  6  745      949.99              0               10   \n",
       "3                  6  129     2949.99              0               24   \n",
       "4                  6  697      657.99              0               17   \n",
       "...              ...  ...         ...            ...              ...   \n",
       "740089             1   48      504.88              0                2   \n",
       "740090             1  182     1717.95              0               23   \n",
       "740091             1  109     1659.88              0                5   \n",
       "740092             1  184      909.96              0                9   \n",
       "740093             1  446      619.98              1                1   \n",
       "\n",
       "        product_department  product_category  origin_country  process_costing  \\\n",
       "0                        3                11               0                0   \n",
       "1                        4                 9               0                1   \n",
       "2                        4                12               0                1   \n",
       "3                        4                11               0                1   \n",
       "4                        4                 9               0                1   \n",
       "...                    ...               ...             ...              ...   \n",
       "740089                   4                 9               0                1   \n",
       "740090                   4                11               0                1   \n",
       "740091                   4                 9               0                1   \n",
       "740092                   4                12               0                1   \n",
       "740093                   3                12               1                1   \n",
       "\n",
       "        sku_color  price_status  winning_price  items_sold  \\\n",
       "0              12             3        1488.07           0   \n",
       "1               9             3         392.58           0   \n",
       "2              17             3        1110.69           1   \n",
       "3              21             3        3457.04           0   \n",
       "4              31             2         529.00           0   \n",
       "...           ...           ...            ...         ...   \n",
       "740089          6             2         339.00           0   \n",
       "740090         12             4        1717.95           0   \n",
       "740091         22             2        1093.68           0   \n",
       "740092          5             2         899.96           0   \n",
       "740093         31             3         659.98           0   \n",
       "\n",
       "        avg_website_visits_last_week  stock_qty  month  day  year  \\\n",
       "0                          17.285714          0      1    1  2020   \n",
       "1                          48.857143         56      1    1  2020   \n",
       "2                          22.714286          0      1    1  2020   \n",
       "3                           2.800000          0      1    1  2020   \n",
       "4                           0.000000          0      1    1  2020   \n",
       "...                              ...        ...    ...  ...   ...   \n",
       "740089                     41.000000         61      7    3  2023   \n",
       "740090                    154.142857          1      7    3  2023   \n",
       "740091                    138.000000         16      7    3  2023   \n",
       "740092                     32.714286         20      7    3  2023   \n",
       "740093                     19.000000        136      7    3  2023   \n",
       "\n",
       "        value_dollar  rate_employability  \n",
       "0             4.0949                12.4  \n",
       "1             4.0949                12.4  \n",
       "2             4.0949                12.4  \n",
       "3             4.0949                12.4  \n",
       "4             4.0949                12.4  \n",
       "...              ...                 ...  \n",
       "740089        4.8222                 8.0  \n",
       "740090        4.8222                 8.0  \n",
       "740091        4.8222                 8.0  \n",
       "740092        4.8222                 8.0  \n",
       "740093        4.8222                 8.0  \n",
       "\n",
       "[740094 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa dos dados da Mobly\n",
    "df = pd.read_csv(\"../documentos/outros/base_de_dados/mobly_data_official.csv\", sep = \",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a coluna que se quer prever\n",
    "X = df.drop(['items_sold'], axis=1)\n",
    "y = df['items_sold']\n",
    "\n",
    "# Define os dados de treino e os de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica de Avaliação dos Modelos Candidatos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O texto abaixo foi aproveitado do artefato 3 (3° sprint), conforme combinado com a Orientadora e Instrutor de programação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em princípio, as métricas que serão utilizadas para avaliar o desempenho dos modelos candidatos abaixo são explicadas no notebook _Modelagem_ e são: MAE (Erro Absoluto Médio), MSE (Erro Quadrático Médio), RMSE (Raiz Quadrada do Erro Médio) e _R² Score_ (Coeficiente de Determinação). Mas, mesmo observando todas essas métricas em cada um dos modelos, optamos por ter um foco maior na _R² Score_, uma vez que tal métrica possui uma fácil compreensão e interpretação. Além de que a métrica _R² Score_ consegue expressar uma medida da qualidade geral do modelo em questão, pois ela consegue explicar a variabilidade presente nos dados de saída, os quais são gerados pelo modelo. \n",
    "\n",
    "É válido destacar que a _R² Score_ tem uma extrema relevância para o desenvolvimento da mobil.ia, dado que o modelo precisa prever a quantidade de itens vendidos por SKU com a maior precisão possível (algo destacado tanto pelo TAPI quanto pelos parceiros da Mobly), de modo que a equipe de _Supply Chain_ da organização possa tomar as devidas decisões para equilibrar o abastecimento de estoque. A importância da precisão do modelo desenvolvido está centrada, principalmente, no quanto os resultados gerados pelo algoritmo pode afetar a empresa parceira, pois:\n",
    "* Caso o algoritmo realize uma grande quantidade de previsões corretas (ou minimamente corretas), a Mobly poderá ter o seu lucro aumentado, pois terá produtos disponíveis para suprir as demandas dos seus clientes, sem desperdiçar materiais e, por consequência, sem perder o dinheiro investido. Além de que, por meio dessa disponibilidade, há a possibilidade da Mobly ter mais clientes e, consequentemente, aumentar o seu número de vendas e melhorar a imagem da marca;\n",
    "* Caso o algoritmo realize uma grande quantidade de previsões incorretas, a Mobly poderá ter uma queda no seu lucro, pois a disponibilidade dos produtos pode variar, haja vista que o estoque não será bem abastecido. Além disso, a empresa pode lidar com o desperdício de materiais (e, como consequência, a perda de dinheiro), com a perda de clientes e com a desvalorização da marca.\n",
    "\n",
    "Sendo assim, como a _R² Score_ consegue explicar a variabilidade dos dados de forma mais direta que as demais métricas, ela é de extrema importância para que o modelo preditivo desenvolvido consiga contribuir positivamente para a Mobly, É válido destacar que as outras métricas **não serão descartadas ou ignoradas**, apenas iremos analisar de forma mais concentrada o _R² Score_, além de que essa decisão foi validada com o parceiro de projeto na terceira sprint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização dos hiperparâmetros dos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A otimização dos hiperparâmetros é o método responsável por ajustar as configurações próprias de cada modelo de predição, a fim de buscar aquelas que melhor se encaixam com o conjunto de dados utilizados para treinar esse algoritmo. Dessa forma, essa otimização é utilizada para melhorar o desempenho do modelo, promovendo uma melhor adaptação ao caso específico e ao seu conjunto de dados.\n",
    "\n",
    "Dentre os algoritmos de otimização existentes, os mais utilizados são o **Random search** e o **Grid search**. O **Grid Search** é um algoritmo de otimização de hiperparâmetros relativamente simples e realiza a busca, em um conjunto de dados, de um ou mais hiperparâmetros, de modo a testar todas as combinações possíveis entre eles [1]. Os benefícios desse modelo consistem em uma exploração mais completa e robusta por meio de uma abordagem simples de implementar. Ao mesmo tempo, pode não ser tão viável em alguns casos, como, por exemplo, em _datasets_ muito grandes, podendo ser ineficiente e demorado. \n",
    "\n",
    "Já o **Random Search** possui um funcionamento muito parecido com o algoritmo anterior, porém, ao invés de testar todas as combinações, ele realiza uma busca aleatória, isto é, esse algoritmo testa combinações aleatórias de hiperparâmetros, de acordo com um número especificado de amostras [1]. Entre os benefícios desse algoritmo, é possível destacar a eficiência, uma vez que consegue ser aplicado em um tempo razoável (sendo ideal para datasets maiores) e, ao mesmo tempo, apresentar bons resultados. Entretanto, uma desvantagem desse algoritmo é que não há garantia de encontrar o melhor conjunto de hiperparâmetros, uma vez que não consegue abranger todos os tipos de combinações.\n",
    "\n",
    "A partir disso, o grupo optou por aplicar os dois algoritmos de otimização citados para os modelos escolhidos. A aplicação do algoritmo de otimização será ajustada conforme o desempenho deles em cada modelo, e ao fim, será escolhido o melhor algoritmo para cada modelo e as respectivas métricas resultantes.\n",
    "\n",
    "_[1] Miura, Lucas. Modelos de Predição | Otimização de Hiperparâmetros em Python. Medium, 12 abr. 2020. Disponível em: https://medium.com/turing-talks/modelos-de-predi%C3%A7%C3%A3o-otimiza%C3%A7%C3%A3o-de-hiperpar%C3%A2metros-em-python-3436fc55016e#. Acesso em 18 set. 2023._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> É válido ressaltar que o treinamento dos modelos de Regressão Linear, Árvore de Decisão e Random Forest foi realizado no caderno _Modelagem_ e, como combinado com o instrutor de programação e com a orientadora, serão aproveitados as informações documentadas desse notebook neste atual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente, foi realizado o treinamento do modelo de Regressão Linear no notebook _Modelagem_ e, a partir desse treinamento, foi obtido os seguintes resultados:\n",
    "\n",
    "* **Erro Absoluto Médio (MAE):** 2.3551262630973295\n",
    "* **Erro Quadrático Médio (MSE):** 25.32130884490815\n",
    "* **Raiz quadrada do erro-médio (RMSE):** 5.03202830326978\n",
    "* **Coeficiente de Determinação (R²):** 0.30530596803262156\n",
    "\n",
    "A partir dos resultados acima, optamos por aplicar a otimização por hiperparâmetros para observar se este modelo pode melhorar o seu desempenho. Sendo assim, abaixo será realizada essa otimização:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parâmetros e declaração do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evoca o modelo de regressão linear \n",
    "model_lr = LinearRegression()\n",
    "\n",
    "# Define a grade de hiperparâmetros para pesquisa aleatória\n",
    "param_lr = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'positive': [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Random Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, aplicamos o **Random Search** com 50 iterações, a partir da configuração própria do algoritmo, o `n_iter`, para explorar um amplo espaço de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inteli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=50. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LinearRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;positive&#x27;: [True, False]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LinearRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;copy_X&#x27;: [True, False],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;positive&#x27;: [True, False]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LinearRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'copy_X': [True, False],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'positive': [True, False]},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria um objeto RandomizedSearchCV para procurar os melhores parâmetros\n",
    "random_search = RandomizedSearchCV(model_lr, param_lr, n_iter=50, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Ajusta o modelo aos dados\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desempenho e melhores parâmetros do Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'positive': False, 'fit_intercept': True, 'copy_X': True}\n",
      "Erro Absoluto Médio (MAE): 2.2638277970533385\n",
      "Erro Quadrático Médio (MSE): 20.561296084045583\n",
      "Raiz do Erro Quadrático Médio (RMSE): 4.534456536790884\n",
      "R2 Score: 0.32930899142005177\n"
     ]
    }
   ],
   "source": [
    "# Usa o modelo com os melhores parâmetros para fazer previsões nos dados de teste\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Calcula as métricas com base nos dados de teste\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Imprime o desempenho do modelo com os melhores parâmetros\n",
    "print(\"Melhores hiperparâmetros:\", random_search.best_params_)\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Grid Search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;copy_X&#x27;: [True, False],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;positive&#x27;: [True, False]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;copy_X&#x27;: [True, False],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;positive&#x27;: [True, False]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={'copy_X': [True, False],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'positive': [True, False]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria um objeto GridSearchCV para procurar os melhores parâmetros\n",
    "grid_search = GridSearchCV(model_lr, param_lr, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Ajusta o modelo aos dados de treinamento\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desempenho e melhores parâmetros do Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'copy_X': True, 'fit_intercept': True, 'positive': False}\n",
      "Erro Absoluto Médio (MAE): 2.2638277970533385\n",
      "Erro Quadrático Médio (MSE): 20.561296084045583\n",
      "Raiz do Erro Quadrático Médio (RMSE): 4.534456536790884\n",
      "R2 Score: 0.32930899142005177\n"
     ]
    }
   ],
   "source": [
    "# Usa o modelo com os melhores parâmetros para fazer previsões nos dados de teste\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Calcula as métricas com base nos dados de teste\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Imprime os melhores parâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos os seguintes hiperparâmetro para o **Random Search** e o **Grid Search**:\n",
    "\n",
    "  * `positive`: Quando definido como `True`, impõe a restrição de que os coeficientes do modelo devem ser não negativos. Isso é útil quando você tem conhecimento prévio de que os coeficientes devem ser positivos [2].\n",
    "\n",
    "  * `fit_intercept`: Este parâmetro determina se a intercepção (ou viés) deve ser ajustada no modelo linear. Se for definido como `True`, o modelo ajustará a intercepção. Se for definido como `False`, o modelo não terá uma intercepção e passará pela origem [2]. \n",
    "\n",
    "  * `copy_X`: Este parâmetro determina se os dados de entrada (X) devem ser copiados antes do ajuste do modelo. Quando definido como `True`, uma cópia dos dados é feita para evitar modificações indesejadas. Quando definido como `False`, o modelo ajusta os dados diretamente [2]. \n",
    "\n",
    "Após utilizarmos o algoritmo de otimização de hiperparâmetro **Random Search**, observamos que os melhores hiperparâmetros encontrados foram:\n",
    "\n",
    "`{'positive': False, 'fit_intercept': True, 'copy_X': True}`\n",
    "\n",
    "Além disso, as métricas de desempenho do modelo de Regressão Linear foram as seguintes:\n",
    "\n",
    "* **Erro Absoluto Médio (MAE):** 2.2638277970533385\n",
    "* **Erro Quadrático Médio (MSE):** 20.561296084045583\n",
    "* **Raiz do Erro Quadrático Médio (RMSE):** 4.534456536790884\n",
    "* **R2 Score:** 0.32930899142005177\n",
    "\n",
    "\n",
    "Em seguida, foi aplicado o **Grid Search** para uma busca mais exaustiva de hiperparâmetros. Os melhores hiperparâmetros encontrados foram:\n",
    "\n",
    "`{'copy_X': True, 'fit_intercept': True, 'positive': False}`\n",
    "\n",
    "Surpreendentemente, os resultados após a otimização com o **Grid Search** foram idênticos aos obtidos com o **Random Search**:\n",
    "\n",
    "* **Erro Absoluto Médio (MAE):** 2.2638277970533385\n",
    "* **Erro Quadrático Médio (MSE):** 20.561296084045583\n",
    "* **Raiz do Erro Quadrático Médio (RMSE):** 4.534456536790884\n",
    "* **R2 Score:** 0.32930899142005177\n",
    "\n",
    "É evidente que, mesmo após a otimização de hiperparâmetros, as métricas de desempenho do modelo de Regressão Linear não apresentaram uma melhoria significativa. Isso ressalta a conclusão de que, para o caso deste projeto em específico, a Regressão Linear pode não ser o modelo mais apropriado, haja vista que o modelo candidato definido no notebook _Modelagem_ apresentou um _R²_, o qual corresponde a principal métrica que estamos utilizando para avaliar os modelos, de, aproximadamente, 68%, bem mais alto do que o valor dessa mesma métrica gerado pela otimização do modelo de Regressão Linear, que é, aproximadamente, 32%. Portanto, considerando esses resultados, pode ser apropriado explorar modelos mais complexos ou adequados para o problema em questão.\n",
    "\n",
    "[2] scikit-learn. Scikit-learn: Machine Learning in Python. Versão 0.24.2. 2021. Disponível em: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Árvore de Decisão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente, foi realizado o treinamento do modelo de Árvore de Decisão no notebook _Modelagem_ e, a partir desse treinamento, foi obtido os seguintes resultados:\n",
    "\n",
    "* **Erro Absoluto Médio (MAE):** 2.3976261886782666\n",
    "* **Erro Quadrático Médio (MSE):** 26.63081900872144\n",
    "* **Raiz quadrada do erro-médio (RMSE):** 5.160505693119759\n",
    "* **Coeficiente de Determinação (R²):** 0.269379353765814\n",
    "\n",
    "A partir dos resultados acima, optamos por aplicar a otimização por hiperparâmetros para observar se este modelo pode melhorar o seu desempenho. Sendo assim, abaixo será realizada essa otimização:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parâmetros e declaração do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo de árvore de decisão de regressão\n",
    "model_dt = DecisionTreeRegressor()\n",
    "\n",
    "# Define as distribuições para amostrar hiperparâmetros\n",
    "param_dt = {\n",
    "    'max_depth': np.arange(3, 15),\n",
    "    'min_samples_split': np.arange(2, 21),\n",
    "    'min_samples_leaf': np.arange(1, 11)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Random Search \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como ocorreu no modelo de Regressão Linear, aplicamos o algoritmo de otimização de hiperparâmetro **Random Search** no modelo de Árvore de Decisão com 50 iterações. Essa escolha de iterações está atrelada a possibilidade de se observar um amplo espaço de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# Usa RandomizedSearchCV para encontrar hiperparâmetros aleatórios\n",
    "random_search = RandomizedSearchCV(model_dt, param_dt, n_iter=50, cv=5, scoring='neg_mean_squared_error', verbose=1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtém os melhores hiperparâmetros encontrados\n",
    "best_hyperparameters = random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desempenho e melhores parâmetros do Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'min_samples_split': 3, 'min_samples_leaf': 9, 'max_depth': 14}\n",
      "Erro Absoluto Médio (MAE): 1.635208667994986\n",
      "Erro Quadrático Médio (MSE): 10.968605076594836\n",
      "Raiz do Erro Quadrático Médio (RMSE): 3.3118884456748896\n",
      "R2 Score: 0.6422139552163348\n"
     ]
    }
   ],
   "source": [
    "# Treina o modelo com os melhores hiperparâmetros encontrados\n",
    "y_pred = DecisionTreeRegressor(**best_hyperparameters)\n",
    "y_pred.fit(X_train, y_train)\n",
    "\n",
    "# Faz previsões no conjunto de teste\n",
    "predictions = y_pred.predict(X_test)\n",
    "\n",
    "# Avalia o desempenho do modelo com os melhores hiperparâmetros\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)  \n",
    "mae = mean_absolute_error(y_test, predictions)  \n",
    "r2 = r2_score(y_test, predictions) \n",
    "\n",
    "print(\"Melhores hiperparâmetros:\", random_search.best_params_)\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2280 candidates, totalling 11400 fits\n"
     ]
    }
   ],
   "source": [
    "# Usa GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "grid_search = GridSearchCV(model_dt, param_dt, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtém os melhores hiperparâmetros encontrados\n",
    "best_hyperparameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desempenho e melhores parâmetros do Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Erro Absoluto Médio (MAE): 1.7889991501447182\n",
      "Erro Quadrático Médio (MSE): 12.851929378070077\n",
      "Raiz do Erro Quadrático Médio (RMSE): 3.5849587693682166\n",
      "R2 Score: 0.580781608243827\n"
     ]
    }
   ],
   "source": [
    "# Treina o modelo com os melhores hiperparâmetros encontrados\n",
    "y_pred = DecisionTreeRegressor(**best_hyperparameters)\n",
    "y_pred.fit(X_train, y_train)\n",
    "\n",
    "# Faz previsões no conjunto de teste\n",
    "predictions = y_pred.predict(X_test)\n",
    "\n",
    "# Avalia o desempenho do modelo com os melhores hiperparâmetros\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)  \n",
    "mae = mean_absolute_error(y_test, predictions)  \n",
    "r2 = r2_score(y_test, predictions) \n",
    "\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após utilizarmos o algoritmo de otimização por hiperparâmetros **Random Search**, observamos que os melhores hiperparâmetros encontrados foram:\n",
    "\n",
    "`{'min_samples_split': 3, 'min_samples_leaf': 9, 'max_depth': 14}`\n",
    "\n",
    "A partir da obtenção dos hiperparâmetros acima, através do **Random Search** aplicado ao algoritmo de Árvore de Decisão, é necessário compreender, de maneira abrangente, o significado de cada um deles, bem como a capacidade que possuem de afetar o desempenho do modelo de Árvore de Decisão. Nesse sentido, abaixo será definido cada um dos hiperparâmetros:\n",
    "\n",
    "* **min_samples_split:** Trata-se de um hiperparâmetro  que define o \"número mínimo de amostras necessárias para dividir um nó interno\" [3]. Esse hiperparâmetro controla o quão \"criteriosa\" a árvore deve ser ao decidir dividir um nó interno em subnós. No caso do modelo em questão, o número mínimo de amostras necessárias para dividir um nó interno é três.\n",
    "* **min_samples_leaf:** Esse hiperparâmetro trata-se do \"número mínimo de amostras necessárias para estar em um nó folha\" [3]. Esse hiperparâmetro afeta o tamanho mínimo permitido para um nó folha. Sendo assim, neste modelo o número mínimo de amostras necessárias para estar em um nó fola é nove.\n",
    "* **max_depth:** Por fim, esse hiperparâmetro define a \"profundidade máxima das árvores\" [3]. A profundidade de uma árvore de decisão determina até que ponto ela pode se ramificar, o que impacta a complexidade do modelo. A partir disso, a profundidade máxima deste modelo é 14.\n",
    "\n",
    "Além disso, as métricas de desempenho do modelo de Árvore de Decisão, com o **Random Search** aplicado, foram as seguintes:\n",
    "\n",
    "* **Erro Absoluto Médio (MAE):** 1.6351466432565025\n",
    "* **Erro Quadrático Médio (MSE):** 10.969213266190533\n",
    "* **Raiz quadrada do erro-médio (RMSE):** 3.311980263556915\n",
    "* **Coeficiente de Determinação (R²):** 0.6421941166180443 \n",
    "\n",
    "Através desses resultados é possível notar que a otimização de hiperparâmetros do algoritmo **Random Search** é bastante eficiente, pois o valor da métrica principal, o _R²_, é de 26% aproximadamente no modelo sem otimização e com a otimização aplicada ao modelo, o valor de _R²_ aumenta para, aproximadamente, 64%. Esse resultado, quando comparado com a otimização máxima do modelo de Regressão Linear, indica que o modelo de Árvore de Decisão possui um melhor desempenho com os dados utilizados neste projeto. Porém, quando este algoritmo é comparado com o modelo **Random Forest** sem nenhuma otimização, o valor de _R²_ é menor, uma vez que tal métrica do **Random Forest** é de 68% aproximadamente. Com isso, é possível encontrar outra forma de otimizar ainda mais o _R²_ do modelo de Árvore de Decisão. \n",
    "\n",
    "Em seguida, foi aplicado o **Grid Search** para uma busca mais exaustiva de hiperparâmetros. Os melhores hiperparâmetros encontrados foram:\n",
    "\n",
    "`{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5}`\n",
    "\n",
    "Anteriormente foi explicado a definição desses mesmos hiperparâmetros, porém é válido ressaltar o que cada resultado significa. Com isso, o `max_depth` indica que a profundidade máxima das árvores é dez. Já o `min_samples_leaf` define que o número mínimo de amostras necessárias para estar em um nó folha é quatro. Por fim, o `min_samples_split` indica que o número mínimo de amostras necessárias para dividir um nó interno é cinco. \n",
    "\n",
    "Com isso, as métricas obtidas através do **Grid Search**, aplicado ao modelo de Árvore de Decisão, foram:\n",
    "* **Erro Absoluto Médio (MAE):** 1.7888623000764408\n",
    "* **Erro Quadrático Médio (MSE):** 12.850584895123045\n",
    "* **Raiz quadrada do erro-médio (RMSE):** 3.584771247251775\n",
    "* **Coeficiente de Determinação (R²):** 0.5808254640698448\n",
    "\n",
    "Os resultados das métricas apresentados acima evidenciam que o **Grid Search** oferece uma melhoria para o modelo de Árvore de Decisão, haja vista que o _R²_ gerado é maior (58%) que a mesma métrica do modelo sem otimização (26%). Mas, em relação à otimização anterior, é evidente que o _R²_ é maior no algoritmo **Random Search**, que é 64%, do que neste algoritmo, que é 58%. \n",
    "\n",
    "Portanto, é válido ressaltar que mesmo com as duas otimizações aplicadas, o modelo de Árvore de Decisão não se comportou melhor que o modelo de **Random Forest**.\n",
    "\n",
    "_[3] Faboci, Bruno. Otimizando Random Forest com GridSearch. LinkedIn. Disponível em: https://www.linkedin.com/pulse/otimizando-random-forest-com-gridsearch-bruno-faboci/?originalSubdomain=pt. Acesso em: 22 de setembro de 2023._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente, foi realizado o treinamento do modelo Random Forest no notebook _Modelagem_ e, a partir desse treinamento, decidimos que tal algoritmo seria o nosso modelo candidato, haja vista que ele gerou a métrica principal de avaliação que está sendo utilizada neste projeto, o _R²_, maior que os demais algoritmos. Sendo assim, o resultado das métricas gerado pelo treinamento do modelo Random Forest, com o mesmo dataset utilizado pelos dois algoritmos detalhados anteriormente (Regressão Linear e Árvore de Decisão), foi: \n",
    "* **Erro Absoluto Médio (MAE):** 1.5389725166963635\n",
    "* **Erro Quadrático Médio (MSE):** 11.448398912332877\n",
    "* **Raiz quadrada do erro-médio (RMSE):** 3.383548272499282\n",
    "* **Coeficiente de Determinação (R²):** 0.6859114017884282\n",
    "\n",
    "A partir dos resultados acima, optamos por aplicar a otimização por hiperparâmetros para observar se este modelo pode melhorar o seu desempenho. \n",
    "\n",
    "No caso do modelo Random Forest, o grupo optou por testar diferentes iterações dentro do algoritmo de otimização de hiperparâmetro **Random Search**. Assim, a escolha de testar diferentes valores está fundamentada no fato de que o modelo Random Forest leva um tempo considerável para processar o algoritmo de otimização, dificultando executar de uma só vez um número alto de iterações. Nesse sentido, ao testar diferentes números de iterações mais baixos, é possível comparar qual apresenta melhor desempenho.\n",
    "\n",
    "Considerando o que foi exposto no parágrafo acima, será implementado o código referente a otimização de hiperparâmetros por **Randoms Search** com 3, 6 e 9 iterações. \n",
    "\n",
    "Para realizar a otimização de hiperparâmetros de forma eficaz, é fundamental adquirir um entendimento abrangente dos hiperparâmetros que afetam o desempenho do modelo Random Forest, bem como compreender suas respectivas definições. Nesse sentido, recorremos às definições propostas por Bruno Faboci [3], as quais esclarecem os seguintes hiperparâmetros:\n",
    "\n",
    "* **n_estimators:** Este parâmetro representa o \"número de árvores na floresta\". Ele influencia diretamente a quantidade de árvores de decisão que serão combinadas para formar o ensemble.\n",
    "* **max_depth:** Trata-se da \"profundidade máxima das árvores\". A profundidade de uma árvore de decisão determina até que ponto ela pode se ramificar, o que impacta a complexidade do modelo.\n",
    "* **min_samples_split:** Aqui, nos referimos ao \"número mínimo de amostras necessárias para dividir um nó interno\". Esse hiperparâmetro controla o quão \"criteriosa\" a árvore deve ser ao decidir dividir um nó interno em subnós.\n",
    "* **min_samples_leaf:** Por último, mas não menos importante, temos o \"número mínimo de amostras necessárias para estar em um nó folha\". Esse hiperparâmetro afeta o tamanho mínimo permitido para um nó folha.\n",
    "\n",
    "Tendo em mente essas definições cruciais, prosseguimos com as seguintes otimizações:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parâmetros e declaração do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade de hiperparâmetros\n",
    "param_rf= {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# EVoca o modelo Random Forest\n",
    "model_rf = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Random Search com três iterações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona e realiza o random search\n",
    "random_3 = RandomizedSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_distributions=param_rf, \n",
    "    n_iter=3,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treina o modelo com os hiperparâmetros\n",
    "random_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(random_3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a previsão com os melhores hiperparâmetros\n",
    "best_rf = random_3.best_estimator_\n",
    "y_pred_random_3 = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia com a otimização por random search\n",
    "mse_random_3 = mean_squared_error(y_test, y_pred_random_3)\n",
    "r2_random_3 = r2_score(y_test, y_pred_random_3)\n",
    "mae_random_3 = mean_absolute_error(y_test, y_pred_random_3)\n",
    "rmse_random_3 = sqrt(mse_random_3 )\n",
    "\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae_random_3}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse_random_3}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse_random_3}\")\n",
    "print(f\"R2 Score: {r2_random_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Random Search com seis iterações \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona e realizando o random search\n",
    "random_6 = RandomizedSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_distributions=param_rf, \n",
    "    n_iter=6,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treina o modelo com os hiperparâmetros\n",
    "random_6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(random_6.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a previsão com os melhores hiperparâmetros\n",
    "best_rf = random_6.best_estimator_\n",
    "y_pred_random_6 = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia com a otimização por random search\n",
    "mse_random_6 = mean_squared_error(y_test, y_pred_random_6)\n",
    "r2_random_6 = r2_score(y_test, y_pred_random_6)\n",
    "mae_random_6 = mean_absolute_error(y_test, y_pred_random_6)\n",
    "rmse_random_6 = sqrt(mse_random_6 )\n",
    "\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae_random_6}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse_random_6}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse_random_6}\")\n",
    "print(f\"R2 Score: {r2_random_6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Random Search com nove iterações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona e realiza o random search\n",
    "random_9 = RandomizedSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_distributions=param_rf, \n",
    "    n_iter=9,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treina o modelo com os hiperparâmetros\n",
    "random_9.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(random_9.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a previsão com os melhores hiperparâmetros\n",
    "best_rf = random_9.best_estimator_\n",
    "y_pred_random_9 = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia com a otimização por random search\n",
    "mse_random_9 = mean_squared_error(y_test, y_pred_random_9)\n",
    "r2_random_9 = r2_score(y_test, y_pred_random_9)\n",
    "mae_random_9 = mean_absolute_error(y_test, y_pred_random_9)\n",
    "rmse_random_9 = sqrt(mse_random_9 )\n",
    "\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae_random_9}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse_random_9}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse_random_9}\")\n",
    "print(f\"R2 Score: {r2_random_9}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização por Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em relação ao algoritmo de **Grid Search**, a decisão tomada foi de aplicá-lo de forma reduzida. Isso porque, como o _dataset_ utilizado para o desenvolvimento deste projeto é extenso, o tempo de execução do algoritmo é muito alto, não tornando viável para o projeto executá-lo em sua integridade.Assim sendo, o `param_grid` (uma grade de parâmetros) foi diminuído, a fim de conseguir executar o **Grid Search** e comparar os seus resultados com os apresentados no algoritmo anterior. O `param_grid` é um conjunto predefinido de combinações de hiperparâmetros que o **Grid Search** explora sistematicamente para encontrar a configuração mais adequada para um modelo de aprendizado de máquina [2]. Reduzir o tamanho do `param_grid` significa considerar menos combinações de hiperparâmetros durante a busca, o que pode economizar tempo computacional.\n",
    "\n",
    "_[4] Lewis, Christopher. Optimize Hyperparameters with GridSearch. Medium, 7 mai. 2021. Disponível em: https://medium.com/analytics-vidhya/optimize-hyperparameters-with-gridsearch-d351b0fd339d. Acesso em: 21 set. 2023._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os parâmetros de Grid Search a seguir representam aqueles que idealmente testaríamos, baseados naqueles que foram \n",
    "# utilizados para o algoritmo de random search.\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],      # Número de árvores na floresta\n",
    "#     'max_depth': [None, 10, 20, 30],    # Profundidade máxima das árvores\n",
    "#     'min_samples_split': [2, 5, 10],    # Número mínimo de amostras necessárias para dividir um nó\n",
    "#     'min_samples_leaf': [1, 2, 4]       # Número mínimo de amostras necessárias em uma folha\n",
    "# }\n",
    "\n",
    "\n",
    "# Entretanto, como dentro dessas configurações o algoritmo tem um tempo de processamento maior que 10 horas, \n",
    "# o grupo optou por reduzir esses parâmetros a fim de apresentar a otimização com Grid Search, resultando no \n",
    "# seguinte códgio:\n",
    "\n",
    "# Grade de hiperparâmetros\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "param_grid = {\n",
    "     'n_estimators': [200],      \n",
    "     'max_depth': [5],    \n",
    "     'min_samples_split': [5],    \n",
    "     'min_samples_leaf': [4]       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona e realiza o grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treina o o modelo com os hiperparâmetros\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a previsão com os melhores hiperparâmetros\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_grid = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia com a otimização por grid search\n",
    "mse_grid= mean_squared_error(y_test, y_pred_grid)\n",
    "r2_grid = r2_score(y_test, y_pred_grid)\n",
    "mae_grid = mean_absolute_error(y_test, y_pred_grid)\n",
    "rmse_grid= sqrt(mse_grid )\n",
    "\n",
    "print(f\"Erro Absoluto Médio (MAE): {mae_grid}\")\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse_grid}\")\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse_grid}\")\n",
    "print(f\"R2 Score: {r2_grid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após aplicarmos o **Random Search** no modelo Random Forest as métricas obtidas por meio da otimização de hiperparâmetros foram:\n",
    "* **Random Search aplicado ao Random Forest com três iterações:**\n",
    "  * **Erro Absoluto Médio (MAE):** 1.4559071270701858\n",
    "  * **Erro Quadrático Médio (MSE):** 8.291097825027418\n",
    "  * R-squared: 0.7295518366268021\n",
    "  * **Raiz quadrada do erro-médio (RMSE):** 2.879426648662441\n",
    "  * **Coeficiente de Determinação (R²):** 0.7295518366268021\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "* **Random Search aplicado ao Random Forest com seis iterações:**\n",
    "  * **Erro Absoluto Médio (MAE):** 1.4544637332616124\n",
    "  * **Erro Quadrático Médio (MSE):** 8.265656812026746\n",
    "  * **Raiz quadrada do erro-médio (RMSE):** 2.8750055325210675\n",
    "  * **Coeficiente de Determinação (R²):** 0.7303816996178786\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "* **Random Search aplicado ao Random Forest com nove iterações:**\n",
    "  * **Erro Absoluto Médio (MAE):** 1.4643446317746063\n",
    "  * **Erro Quadrático Médio (MSE):** 8.291285890774173\n",
    "  * **Raiz quadrada do erro-médio (RMSE):** 2.879459305281839\n",
    "  * **Coeficiente de Determinação (R²):**  0.7295457020910776\n",
    "\n",
    "É possível observar que o algoritmo de otimização de hiperparâmetro **Random Search** realmente consegue melhorar o desempenho do modelo **Random Fores**, haja vista que a principal métrica escolhida para ser observada, o _R²_, possui, originalmente, o valor de, aproximadamente, 68%. Mas, após ser aplicada a otimização de hiperparâmetro com o **Random Search de seis iterações**, o _R²_ alcançou um valor superior de, aproximadamente, 73%. Isso significa que, de fato, tal algoritmo de otimização de hiperparâmetro consegue otimizar o modelo **Random Forest**. \n",
    "\n",
    "Ademais, é válido destacar que os melhores hiperparâmetros encontrados com o **Random Search de seis iterações** foram:\n",
    "`{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 20}`\n",
    "\n",
    "A partir da definição realizada anteriormente, o hiperparâmetro `n_estimators` gerado indica que a quantidade de árvores necessárias para o algoritmo é 200. Já o `min_samples_split` diz que o número mínimo de amostras necessárias para dividir um nó interno é cinco. O `min_samples_leaf` aponta que o número mínimo de amostras necessárias para estar em um nó folha é um e, por fim, o valor de `max_depth` demonstra que a profundidade das árvores é 20.   \n",
    "\n",
    "As métricas obtidas através do **Grid Search**, aplicado ao modelo de Random Forest, foram:\n",
    "* **Erro Absoluto Médio (MAE):** 17.80755335081607\n",
    "* **Erro Quadrático Médio (MSE):** 8.291285890774173\n",
    "* **Raiz quadrada do erro-médio (RMSE):** 4.219899684923337\n",
    "* **Coeficiente de Determinação (R²):** 0.4191336057619707\n",
    "\n",
    "Tendo em vista os resultados das métricas gerados pelo algoritmo de otimização de hiperparâmetros **Grid Search**, é possível observar que não há uma melhora das métricas do algoritmo **Random Forest**, haja vista que a métrica principal, o _R²_, possui o valor de 68% no modelo sem a otimização de hiperparâmetro e o _R²_ gerado pela otimização em questão assume o valor de, aproximadamente, 42%. Diante disso, é notório que o **Grid Search** não otimizou o modelo, mas, sim, piorou os seus resultados. \n",
    "\n",
    "Ademais, é válido destacar que os melhores hiperparâmetros encontrados com o **Grid Search** foram:\n",
    "`{'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}`\n",
    "\n",
    "Com isso, tendo em vista a definição realizada anteriormente, o `max_depth` demonstra que a profundidade das árvores devem ser cinco. Já o `min_samples_leaf` aponta que o número mínimo de amostras necessárias para estar em um nó folha é quatro. O `min_samples_split` diz que o número mínimo de amostras necessárias para dividir um nó interno é cinco e, por fim, o `n_estimators` gerado indica que a quantidade de árvores necessárias para o algoritmo é 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo escolhido e justificativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o desempenho dos diferentes modelos, nomeadamente o **Random Forest**, a **Regressão Linear** e a **Árvore de Decisão**, juntamente com as respetivas otimizações de hiperparâmetros, a escolha recaiu sobre o **Random Forest** com otimização através do método de **Random Search**, com um total de 6 iterações. Esta seleção baseia-se na comparação das métricas obtidas anteriormente, revelando-se o mais eficiente, como destacado a seguir:\n",
    "\n",
    "\n",
    "- **Random Search aplicado ao Random Forest com seis iterações:**\n",
    "  - **Erro Absoluto Médio (MAE):** 1.4544637332616124\n",
    "  - **Erro Quadrático Médio (MSE):** 8.265656812026746\n",
    "  - **Raiz Quadrada do Erro Médio (RMSE):** 2.8750055325210675\n",
    "  - **Coeficiente de Determinação (R²):** 0.7303816996178786\n",
    "\n",
    "Os resultados obtidos estão em harmonia com os objetivos específicos do modelo, como explicado em maior detalhe no tópico **4.3.3**. O algoritmo Random Forest é robusto e abrangente, permitindo uma avaliação minuciosa das características do conjunto de dados e fornecendo previsões precisas.\n",
    "\n",
    "Para uma melhor compreensão da qualidade das previsões efetuadas por este modelo, é necessário uma análise mais aprofundada das métricas. O MAE de cerca de 1.45 e o RMSE de aproximadamente 2.87 indicam que, em média, o modelo pode errar em cerca de 1.45 e 2.87 unidades nas previsões de vendas de produtos, o que é considerado satisfatório, dadas as metas do projeto. O valor de R², que se aproxima de 73%, significa que é possível explicar uma parte significativa da variabilidade das características nos valores alvo, o que também é relevante para os objetivos do projeto. O RMSE, que penaliza erros mais significativos, situa-se em cerca de 8.26, indicando que existem previsões que se desviam consideravelmente dos valores reais, sendo um ponto a ter em consideração, embora não represente uma queda drástica no desempenho.\n",
    "\n",
    "Portanto, com base na análise anteriormente realizada, o modelo selecionado efetua previsões satisfatórias do número de vendas da empresa Mobly, sendo essencial para o propósito de otimizar a gestão de estoque e melhorar a eficiência das operações de entrega."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
